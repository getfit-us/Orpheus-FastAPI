services:
  orpheus-fastapi:
    container_name: orpheus-fastapi
    build:
      context: .
      dockerfile: Dockerfile.gpu
      
    ports:
      - "5005:5005"
    env_file:
      - .env
    environment:
      - ORPHEUS_API_URL=http://vllm-server:8000/v1/completions
      - NUM_OF_WORKERS=1
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped
    depends_on:
      vllm-server:
        condition: service_started

  vllm-server:
    image: vllm/vllm-openai:latest
    gpus: all

    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    environment:
      HUGGING_FACE_HUB_TOKEN:
    ports:
      - 8880:8000
    ipc: host
    command: --model getfit/orpheus-3b-0.1-ft-FP8-Dynamic --served-model-name orpheus --max-model-len 32768 --gpu-memory-utilization 0.8
